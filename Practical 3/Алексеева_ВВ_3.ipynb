{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoK0UrGtAOlo"
      },
      "source": [
        "# Практическая работа №3. Свёрточные нейронные сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kkoxPG8AXsj"
      },
      "source": [
        "**Работу выполнила:**\n",
        "\n",
        "Алексеева Влада Вадимовна, ИТМО ID 367801"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJHy7vziiPnC"
      },
      "source": [
        "# Классификация цветов с помощью свёрточных нейронных сетей.\n",
        "\n",
        "\n",
        "В работе необходимо познакомится с различными архитектурами сверхточных нейронных сетей и их обучением на GPU (англ. graphics processing, графический процессор) на языке программирования Python 3 и фреймворка Torch (PyTorch).  Для этого предлагается использовать ресурсы Google Colab - Colaboratory, для выполнения вычислений на GPU. После с ознакомления, выполнить практическое задане в конце данной тетради (notebook).\n",
        "\n",
        "Рассмотрим [Датасет](https://www.kaggle.com/alxmamaev/flowers-recognition ) содержащий 4242 изображения цветов размеченных по 5 видам (тюльпан, ромашка, подсолнух, роза, одуванчик). Данный набор данных можно скачать по [ссылке](https://www.kaggle.com/alxmamaev/flowers-recognition ) с сайте kaggle.\n",
        "\n",
        "Загрузите папку с картинками на гугл диск, чтобы не загружать ее каждый раз заново при перезапуске колаба. Структура файлов (можно посмотреть в меню слева) может быть такой: '/content/drive/My Drive/data/flowers'.\n",
        "\n",
        "Обязательно подключите аппаратный ускоритель (GPU) к среде выполнения. В меню сверху: Среда выполнения -> Сменить среду выполнения\n",
        "\n",
        "Первым делом разберите более детально код выполнив код ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRteSKZ5VKai"
      },
      "source": [
        "# Подготовка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtAgtr2V3u6"
      },
      "source": [
        "Загружаем библиотеки. Фиксируем random.seed для воспроизводимости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kvM84NDjxCnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b63dec-9204-4e2e-e617-9130a2dfad41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e4a24378d90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjYDp6nXWWmQ"
      },
      "source": [
        "Выбираем на чем будем делать вычисления - CPU или GPU (cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "code",
        "id": "FzyQGtNfzMsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adeac47-ff3d-414a-df4a-c281dfac9820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AUK8d5HKdYB"
      },
      "source": [
        "Блок для соединения с Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NrcMAZywKnKK",
        "outputId": "bc71105f-31e4-40b7-d412-6b791fdf8536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "FOLDERNAME = 'Datas'\n",
        "\n",
        "assert FOLDERNAME is not None, '[!] Enter the foldername.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aV-txOlLyJhK"
      },
      "outputs": [],
      "source": [
        "prepare_imgs = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize((224, 224)), # Приводим картинки к одному размеру\n",
        "        torchvision.transforms.ToTensor(), # Упаковывем их в тензор\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] # Нормализуем картинки по каналам\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "# Задаем датасет\n",
        "dataset = ImageFolder('/content/drive/My Drive/Datas', transform=prepare_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BcuefCcB8iwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ae7645-8d17-4fc8-f037-17542277bd27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/Datas/Daisy/10172379554_b296050f82_n.jpg', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset.imgs[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u_DuonGn5HVb"
      },
      "outputs": [],
      "source": [
        "class ValueMeter(object):\n",
        "  \"\"\"\n",
        "  Вспомогательный класс, чтобы отслеживать loss и метрику\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "      self.sum = 0\n",
        "      self.total = 0\n",
        "\n",
        "  def add(self, value, n):\n",
        "      self.sum += value*n\n",
        "      self.total += n\n",
        "\n",
        "  def value(self):\n",
        "      return self.sum/self.total\n",
        "\n",
        "def log(mode, epoch, loss_meter, accuracy_meter, best_perf=None):\n",
        "  \"\"\"\n",
        "  Вспомогательная функция, чтобы\n",
        "  \"\"\"\n",
        "  print(\n",
        "      f'[{mode}] Epoch: {epoch:0.2f}. '\n",
        "      f'Loss: {loss_meter.value():.2f}. '\n",
        "      f'Accuracy: {100 * accuracy_meter.value():.2f}% ', end='\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rhIMxkeVTGj"
      },
      "source": [
        "# Сверточная нейросеть с нуля\n",
        "\n",
        "## Вручную прописываем слои"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj-pqIyFoAr0"
      },
      "source": [
        "**Как работает блок 'Сверточная нейросеть с нуля'? Как можно описать сверточный и пулинговый слой?**\n",
        "\n",
        "Этот блок определяет простую последовательную архитектуру CNN с помощью `nn.Sequential`.\n",
        "\n",
        "*   **Сверточный слой (`nn.Conv2d`):** Это основной строительный блок CNN. Он применяет набор обучаемых фильтров (ядер) к входному изображению. Каждый фильтр скользит по изображению, вычисляя скалярное произведение между своими весами и локальным участком изображения. Результат — карта признаков (feature map), которая активируется, если на изображении присутствует признак, за который 'отвечает' этот фильтр (например, вертикальный край). Параметры: `in_channels` (входные каналы), `out_channels` (количество фильтров), `kernel_size` (размер фильтра), `stride` (шаг), `padding` (отступ).\n",
        "\n",
        "*   **Пулинговый слой (`nn.MaxPool2d`):** Этот слой выполняет даунсэмплинг (уменьшение пространственного размера) карт признаков. `MaxPool2d` выбирает максимальное значение из каждой небольшой локальной области (например, 2x2). Это помогает:\n",
        "    1. Уменьшить количество параметров и вычислений в сети.\n",
        "    2. Сделать представление признаков немного инвариантным к небольшим сдвигам и искажениям.\n",
        "    3. Сжать информацию, оставляя наиболее значимые активации.\n",
        "\n",
        "Архитектура работает по принципу: чередование сверточных слоев (для извлечения признаков) и пулинговых слоев (для уменьшения размерности), после чего данные 'выравниваются' (`Flatten`) и подаются на полносвязные слои (`Linear`) для окончательной классификации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IeRibccoyT_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ce8e0c-3404-4387-f4ee-b1a01318fba3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): ReLU()\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): ReLU()\n",
              "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): ReLU()\n",
              "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU()\n",
              "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (13): ReLU()\n",
              "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (15): Flatten(start_dim=1, end_dim=-1)\n",
              "  (16): Linear(in_features=200704, out_features=1024, bias=True)\n",
              "  (17): ReLU()\n",
              "  (18): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (19): ReLU()\n",
              "  (20): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # Выход: 64 x 16 x 16\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # Выход: 128 x 8 x 8\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # Выход: 256 x 4 x 4\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 28 * 28, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 5))\n",
        "\n",
        "model.to(device) # Отправляем модель на девайс (GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP0M3cL8ZDd3"
      },
      "source": [
        "# Задаем параметры и функцию для обучения. Разбиваем датасет на train/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iwhX2vdquink"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "optimizer = torch.optim.Adam(params = model.parameters())\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG0zjMWDYu32"
      },
      "source": [
        "Разбиваем датасет на train и validation\n",
        "\n",
        "Задаем dataloader'ы - объекты для итеративной загрузки данных и лейблов для обучения и валидации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D2AW1YTupITs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42da9db3-9bf7-4f8e-b59e-8c7331bb8278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающего и валидационного датасета:  3352 1000\n"
          ]
        }
      ],
      "source": [
        "train_set, val_set = torch.utils.data.random_split(dataset, [len(dataset)-1000, 1000])\n",
        "print('Размер обучающего и валидационного датасета: ', len(train_set), len(val_set))\n",
        "\n",
        "loaders = {'training': DataLoader(train_set, batch_size, pin_memory=True,num_workers=2, shuffle=True),\n",
        "           'validation':DataLoader(val_set, batch_size, pin_memory=True,num_workers=2, shuffle=False)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuiJKWrYZZgb"
      },
      "source": [
        "Функция для подсчета Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xm15u4TsDcIY"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzW60Io-riGV"
      },
      "source": [
        "Функция для обучения и валидации модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hdlXyjEGhU4W"
      },
      "outputs": [],
      "source": [
        "def trainval(model, loaders, optimizer, epochs=10):\n",
        "    \"\"\"\n",
        "    model: модель, которую собираемся обучать\n",
        "    loaders: dict с dataloader'ами для обучения и валидации\n",
        "    \"\"\"\n",
        "    loss_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "    accuracy_meter = {'training': ValueMeter(), 'validation': ValueMeter()}\n",
        "\n",
        "    loss_track = {'training': [], 'validation': []}\n",
        "    accuracy_track = {'training': [], 'validation': []}\n",
        "\n",
        "    for epoch in range(epochs): # Итерации по эпохам\n",
        "        for mode in ['training', 'validation']: # Обучение - валидация\n",
        "            # Считаем градиаент только при обучении:\n",
        "            with torch.set_grad_enabled(mode == 'training'):\n",
        "                # В зависимоти от фазы переводим модель в нужный ружим:\n",
        "                model.train() if mode == 'training' else model.eval()\n",
        "                for imgs, labels in tqdm(loaders[mode]):\n",
        "                    imgs = imgs.to(device) # Отправляем тензор на GPU\n",
        "                    labels = labels.to(device)\n",
        "                    bs = labels.shape[0]  # Размер батча (отличается для последнего батча в лоадере)\n",
        "\n",
        "                    preds = model(imgs) # Forward pass - прогоняем тензор с картинками через модель\n",
        "                    loss = F.cross_entropy(preds, labels) # Считаем функцию потерь\n",
        "                    acc = accuracy(preds, labels) # Считаем метрику\n",
        "\n",
        "                    # Храним loss и accuracy для батча\n",
        "                    loss_meter[mode].add(loss.item(), bs)\n",
        "                    accuracy_meter[mode].add(acc, bs)\n",
        "\n",
        "                    # Если мы в фазе обучения\n",
        "                    if mode == 'training':\n",
        "                        optimizer.zero_grad() # Обнуляем прошлый градиент\n",
        "                        loss.backward() # Делаем backward pass (считаем градиент)\n",
        "                        optimizer.step() # Обновляем веса\n",
        "\n",
        "            # В конце фазы выводим значения loss и accuracy\n",
        "            log(mode, epoch, loss_meter[mode], accuracy_meter[mode])\n",
        "\n",
        "            # Сохраняем результаты по всем эпохам\n",
        "            loss_track[mode].append(loss_meter[mode].value())\n",
        "            accuracy_track[mode].append(accuracy_meter[mode].value())\n",
        "\n",
        "    return loss_track, accuracy_track"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMhG1AtAau9k"
      },
      "source": [
        "# Обучаем базовую модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnDPDjYuxMAi"
      },
      "source": [
        "Проверим загрузку видеокарты, прежде чем запустить обучение:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAT9SPrzxZH7"
      },
      "source": [
        "Запускаем обучение на 10 эпох"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czmf2yVKvEYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c810e99a-8dbd-40f8-d0ca-8be17770a6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 34/105 [05:37<08:52,  7.50s/it]"
          ]
        }
      ],
      "source": [
        "loss_track, accuracy_track = trainval(model, loaders, optimizer, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAmfxowdRLfQ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(accuracy_track['training'], label='Training')\n",
        "plt.plot(accuracy_track['validation'], label='Validation')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR0_O_fXQ2s9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def predict_image(img, model):\n",
        "    # Преобразование to a batch of 1\n",
        "    xb = img.unsqueeze(0).to(device)\n",
        "    # Получение прогнозов от модели\n",
        "    yb = model(xb)\n",
        "    # Выбираем индекс с наибольшей вероятностью\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Получение метки класса\n",
        "    return dataset.classes[preds[0].item()]\n",
        "\n",
        "for i in range(1,10):\n",
        "  img, label = val_set[i]\n",
        "  plt.imshow(img.clip(0,1).permute(1, 2, 0))\n",
        "  plt.axis('off')\n",
        "  plt.title('Label: {}, Predicted: {}'.format(dataset.classes[label],predict_image(img, model)))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rtKZrQF0oma"
      },
      "source": [
        "# Практическое задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27qiLUtR011m"
      },
      "source": [
        "\n",
        "\n",
        "В заднии представлена логика выполнения с использованием tensorflow/keras. Выполнять можно как с использованием tensorflow/keras, так и pytorch.\n",
        "\n",
        "1. Необходимо обучить предобученную сверточную архитектуру для задач классификации цветов.\n",
        "\n",
        "В выбранной Вами архитектуре также необходимо **разобраться** с основными её параметрами и принципами работы.\n",
        "\n",
        "Посмотрите как использовать [модели в PyTorch](https://pytorch.org/vision/stable/models.html) для классификации, выберите одну и используя transfer learning до-обучите модель на классификацию цветов. Чтобы это сделать замените ____ в ячейках ниже на работающий код.\n",
        "\n",
        "2. Реализовать свою архитектуру, также как в разделе 'Сверточная нейросеть с нуля'.\n",
        "\n",
        "3. Сравнить три архитектуры (из раздела 'Сверточная нейросеть с нуля', предобученую сверточную архитектуру и свою архитектуру (из п. 2)). Визуализировать полученный результат сравнения.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7p7JYlVntBw"
      },
      "source": [
        "**Что такое transfer learning? Что такое предобученая нейронная сеть?**\n",
        "\n",
        "**Предобученная нейронная сеть** — это модель, которая уже прошла процесс обучения на **большом и разнообразном наборе данных** (например, ImageNet, содержащем 14 миллионов изображений 1000 классов).\n",
        "\n",
        "**Transfer Learning (передача обучения)** — это техника машинного обучения, при которой знания, полученные моделью при решении одной задачи, **переносятся** для решения другой, но связанной задачи.\n",
        "\n",
        "**Как это работает на практике?**\n",
        "\n",
        "1.   Берем предобученную модель (например, ResNet50 на ImageNet).\n",
        "2.   **Замораживаем** большую часть ее слоев (обычно все, кроме последнего).\n",
        "3.   **Заменяем** последний слой (классификатор) на новый, подходящий для нашей задачи (в нашем случае — 5 классов вместо 1000).\n",
        "4.   **Дообучаем** (fine-tune) модель на нашем небольшом датасете. Модель использует свои мощные 'признаковые детекторы' для извлечения информации из наших изображений цветов, а новый классификатор учится интерпретировать эти признаки для нашей конкретной задачи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3L29dCHCS6l"
      },
      "source": [
        "1. Обучение предобученной сверточной архитектуры для задач классификации цветов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZGKQ77DqT31"
      },
      "outputs": [],
      "source": [
        "# Импортируем предобученную модель ResNet50 из torchvision\n",
        "# Параметр `weights` указывает, что мы хотим загрузить веса, предварительно обученные на датасете ImageNet\n",
        "model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if2owZZbm1J-"
      },
      "source": [
        "**Добавьте описание архитектуры** выбранной Вами предобученой сверточной нейронной сети.\n",
        "\n",
        "**ResNet50 (Residual Network 50)** — это глубокая сверточная нейронная сеть, состоящая из **50 слоев** (48 сверточных, 1 MaxPool и 1 Average Pool) . Ее ключевая особенность — использование **остаточных блоков (residual blocks)**. Вместо того чтобы напрямую изучать желаемое отображение `H(x)`, блок изучает **остаточную функцию** `F(x) = H(x) - x`, а затем добавляет вход `x` обратно к выходу: `H(x) = F(x) + x`. Эта 'skip-connection' (обходная связь) позволяет эффективно обучать очень глубокие сети, решая проблему исчезающих градиентов .\n",
        "\n",
        "**Основные параметры:**\n",
        "*   **Вход:** Изображения размером `224x224` пикселей с 3 цветовыми каналами (RGB).\n",
        "*   **Выход:** Вектор из 1000 значений (для ImageNet), который мы заменяем на 5 для нашей задачи.\n",
        "*   **Особенности:** Глубокая архитектура, остаточные связи, высокая точность в задачах классификации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zVgqf7x4aOo"
      },
      "outputs": [],
      "source": [
        "# Функция для 'заморозки' всех слоев модели\n",
        "# Это означает, что градиенты для этих слоев не будут вычисляться, и их веса не будут обновляться во время обучения\n",
        "# Мы делаем это, чтобы сохранить знания, полученные моделью на ImageNet, и обучать только новый, последний слой\n",
        "def set_parameter_requires_grad(model):\n",
        "    for param in model.parameters(): # Проходим по всем параметрам (весам и смещениям) модели\n",
        "        param.requires_grad = False  # Отключаем вычисление градиента для них\n",
        "\n",
        "set_parameter_requires_grad(model) # Применяем функцию к нашей модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VY-e1H7nClF"
      },
      "source": [
        "**Что такое функция для заморозки весов модели?**\n",
        "\n",
        "Функция `set_parameter_requires_grad` устанавливает атрибут `requires_grad` для всех параметров модели в значение `False`. В PyTorch этот атрибут определяет, нужно ли вычислять градиенты для данного параметра во время обратного распространения ошибки (backpropagation). Если `requires_grad=False`, градиенты не вычисляются, и веса не обновляются оптимизатором. Это позволяет 'заморозить' слои предобученной модели, сохраняя их полезные признаки, и обучать только новые слои (например, последний классификатор).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLi35ijOadka"
      },
      "source": [
        "Последний слой (fc в ResNet) отвечает за классификацию на 1000 классов (ImageNet). Нам нужно заменить его на слой с 5 выходами (наши 5 видов цветов)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXqwU5Rd5DYs"
      },
      "outputs": [],
      "source": [
        "# В ResNet50 последний слой называется `fc` (fully connected)\n",
        "# По умолчанию он имеет 1000 выходов (для 1000 классов ImageNet)\n",
        "# Нам нужно заменить его на новый линейный слой с 5 выходами, соответствующими нашим 5 классам цветов (тюльпан, ромашка и т.д.)\n",
        "model.fc = nn.Linear(model.fc.in_features, 5) # `model.fc.in_features` автоматически дает нам количество входов в этот слой (2048 для ResNet50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaquxdRWJ_LK"
      },
      "outputs": [],
      "source": [
        "# Выводим имена только тех параметров, для которых `requires_grad=True`\n",
        "# После наших манипуляций мы должны увидеть только два параметра:\n",
        "# `fc.weight` и `fc.bias` — веса и смещение нашего нового последнего слоя\n",
        "# Все остальные параметры должны быть 'заморожены'\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_LOfUMUaubD"
      },
      "source": [
        "Эта ячейка должна вывести только fc.weight и fc.bias. Это означает, что обучается только новый последний слой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTE0EUG9lh5g"
      },
      "outputs": [],
      "source": [
        "# Отправляем модель на GPU для ускорения вычислений\n",
        "model.to(device)\n",
        "\n",
        "# Создаем оптимизатор. Важно передать в него `model.parameters()`\n",
        "# Поскольку все параметры, кроме последнего слоя 'заморожены', оптимизатор будет обновлять только веса нового слоя\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Запускаем функцию обучения `trainval`, которую мы уже определили ранее\n",
        "# Сохраняем историю потерь и точности в новые переменные, чтобы не перезаписать результаты базовой модели\n",
        "loss_track_resnet, accuracy_track_resnet = trainval(model, loaders, optimizer, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3npGmGBsoZfe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(accuracy_track_resnet['training'], label='Training')\n",
        "plt.plot(accuracy_track_resnet['validation'], label='Validation')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atswap6Qojha"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0).to(device)\n",
        "    yb = model(xb)\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    return dataset.classes[preds[0].item()]\n",
        "\n",
        "for i in range(1,10):\n",
        "  img, label = val_set[i]\n",
        "  plt.imshow(img.clip(0,1).permute(1, 2, 0))\n",
        "  plt.axis('off')\n",
        "  plt.title('Label: {}, Predicted: {}'.format(dataset.classes[label],predict_image(img, model)))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0zHu9uIo1Df"
      },
      "source": [
        "По желанию, можно сохранить веса модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC6KLbr5pBjd"
      },
      "outputs": [],
      "source": [
        "weights_fname = '/content/drive/My Drive/Datas/ResNet50.pth'\n",
        "torch.save(model.state_dict(), weights_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAZ_cU_ZAwFN"
      },
      "source": [
        "2. Своя архитектура"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh-DKUOcwig-"
      },
      "source": [
        "Обновление подготовки данных (Аугментация)\n",
        "\n",
        "Первым делом улучшим `prepare_imgs`, добавив аугментацию. Это искусственно увеличит датасет и сделает модель более устойчивой к вариациям."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6LELpFzwwBz"
      },
      "outputs": [],
      "source": [
        "# Обновленный блок подготовки изображений с аугментацией для обучающей выборки\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((256, 256)), # Сначала увеличиваем\n",
        "    torchvision.transforms.RandomCrop(224),     # Затем случайно обрезаем до 224x224\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5), # Случайное отражение по горизонтали\n",
        "    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2), # Небольшие изменения цвета\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Для валидации аугментация не нужна, только ресайз и нормализация\n",
        "val_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((224, 224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGo7IJYZw0SN"
      },
      "source": [
        "Теперь нужно пересоздать датасеты с новыми трансформациями:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXEXJXSUw3Fo"
      },
      "outputs": [],
      "source": [
        "# Исходный датасет без трансформаций для разделения\n",
        "base_dataset = ImageFolder('/content/drive/My Drive/Datas')\n",
        "\n",
        "# Разделяем индексы\n",
        "train_indices, val_indices = torch.utils.data.random_split(range(len(base_dataset)), [len(base_dataset)-1000, 1000])\n",
        "\n",
        "# Создаем Subset с нужными трансформациями\n",
        "from torch.utils.data import Subset\n",
        "train_set = Subset(base_dataset, train_indices.indices)\n",
        "val_set = Subset(base_dataset, val_indices.indices)\n",
        "\n",
        "# Применяем трансформации\n",
        "train_set.dataset.transform = train_transform\n",
        "val_set.dataset.transform = val_transform\n",
        "\n",
        "# Создаем загрузчики\n",
        "loaders = {\n",
        "    'training': DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2, pin_memory=True),\n",
        "    'validation': DataLoader(val_set, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCWsGxbRxKSB"
      },
      "source": [
        "Эта модель использует **остаточные связи (Residual Connections)** внутри блоков, что позволяет ей быть глубже без риска деградации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdWjA7z1C1CN"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Простой остаточный блок.\n",
        "    Вход и выход должны иметь одинаковое количество каналов и пространственное разрешение.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x # Сохраняем исходный вход\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual # Добавляем исходный вход к выходу сверток\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class EnhancedCNN(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(EnhancedCNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Начальный слой для увеличения количества каналов\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3), # Уменьшаем разрешение сразу\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1), # Дополнительное уменьшение\n",
        "\n",
        "            # Блок 1\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Блок 2\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Блок 3 (самый глубокий)\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            ResidualBlock(512),\n",
        "            ResidualBlock(512),\n",
        "            nn.AdaptiveAvgPool2d((4, 4)) # Фиксируем выходной размер для классификатора\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512 * 4 * 4, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3), # Меньший Dropout перед последним слоем\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86L2N_eZxSKP"
      },
      "source": [
        "Планировщик (`scheduler`) постепенно уменьшает скорость обучения, когда точность на валидации перестает улучшаться. Это помогает модели \"дожать\" последние проценты точности и избежать переобучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx1nOoyQxXDR"
      },
      "outputs": [],
      "source": [
        "# Создаем модель\n",
        "enhanced_model = EnhancedCNN(num_classes=5).to(device)\n",
        "\n",
        "# Оптимизатор и функция потерь\n",
        "optimizer = torch.optim.Adam(enhanced_model.parameters(), lr=0.001, weight_decay=1e-4) # Добавляем L2-регуляризацию\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Планировщик скорости обучения\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "# Функция обучения с поддержкой scheduler\n",
        "def trainval_with_scheduler(model, loaders, optimizer, scheduler, epochs=10):\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    # Словари для хранения истории метрик по всем эпохам\n",
        "    loss_track = {'training': [], 'validation': []}\n",
        "    accuracy_track = {'training': [], 'validation': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for mode in ['training', 'validation']:\n",
        "            # Словари для отслеживания метрик в текущей эпохе\n",
        "            loss_meter = ValueMeter()\n",
        "            accuracy_meter = ValueMeter()\n",
        "\n",
        "            with torch.set_grad_enabled(mode == 'training'):\n",
        "                model.train() if mode == 'training' else model.eval()\n",
        "\n",
        "                for imgs, labels in tqdm(loaders[mode]):\n",
        "                    imgs = imgs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    bs = labels.shape[0]\n",
        "\n",
        "                    # Forward pass\n",
        "                    outputs = model(imgs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    acc = accuracy(outputs, labels) # Используем уже определенную функцию accuracy\n",
        "\n",
        "                    # Обновляем метрики\n",
        "                    loss_meter.add(loss.item(), bs)\n",
        "                    accuracy_meter.add(acc, bs)\n",
        "\n",
        "                    if mode == 'training':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "            # Сохраняем метрики текущей эпохи\n",
        "            epoch_loss = loss_meter.value()\n",
        "            epoch_acc = accuracy_meter.value()\n",
        "            loss_track[mode].append(epoch_loss)\n",
        "            accuracy_track[mode].append(epoch_acc)\n",
        "\n",
        "            # Выводим результаты для текущей фазы\n",
        "            if mode == 'validation':\n",
        "                # Обновление scheduler на основе точности валидации\n",
        "                scheduler.step(epoch_acc)\n",
        "\n",
        "            # Сохранение лучшей модели\n",
        "            if epoch_acc > best_val_acc:\n",
        "                best_val_acc = epoch_acc\n",
        "                torch.save(model.state_dict(), '/content/drive/My Drive/Datas/best_enhanced_model.pth')\n",
        "\n",
        "                # Выводим с указанием лучшей точности\n",
        "                log(mode, epoch, loss_meter, accuracy_meter, best_perf=100 * best_val_acc)\n",
        "            else:\n",
        "                log(mode, epoch, loss_meter, accuracy_meter)\n",
        "\n",
        "    return loss_track, accuracy_track, best_val_acc\n",
        "\n",
        "# Запуск обучения\n",
        "enhanced_model = EnhancedCNN(num_classes=5).to(device)\n",
        "optimizer = torch.optim.Adam(enhanced_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "# Обучаем и получаем историю\n",
        "loss_track_enhanced, accuracy_track_enhanced, best_acc = trainval_with_scheduler(enhanced_model, loaders, optimizer, scheduler, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iOkiynqDFCU"
      },
      "source": [
        "3. Сравнение и вузуализация 3-х архитектур"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sPBiSs_cLe_"
      },
      "source": [
        "Теперь у нас есть три набора данных о точности:\n",
        "\n",
        "'accuracy_track' — от базовой модели из начала ноутбука.\n",
        "\n",
        "'accuracy_track_resnet' — от предобученной ResNet50.\n",
        "\n",
        "'accuracy_track_custom' — от собственной архитектуры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_mSZEZxDNak"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Левый график: Точность на обучающей выборке\n",
        "plt.subplot(1, 2, 1)\n",
        "# Строим кривые обучения для всех трех моделей\n",
        "plt.plot(accuracy_track['training'], label='Базовая (train)', linewidth=2)\n",
        "plt.plot(accuracy_track_resnet['training'], label='ResNet50 (train)', linewidth=2)\n",
        "plt.plot(accuracy_track_enhanced['training'], label='Своя (train)', linewidth=2)\n",
        "plt.title('Точность на обучающей выборке')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Правый график: Точность на валидационной выборке\n",
        "# Он показывает, насколько хорошо модель обобщает на новые данные\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(accuracy_track['validation'], label='Базовая (val)', linewidth=2)\n",
        "plt.plot(accuracy_track_resnet['validation'], label='ResNet50 (val)', linewidth=2)\n",
        "plt.plot(accuracy_track_enhanced['validation'], label='Своя Enhanced (val)', linewidth=2)\n",
        "plt.title('Точность на валидационной выборке')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r_2xT9sAxVx"
      },
      "source": [
        "4.   Интерпретация результатов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEwPBvRvkASl"
      },
      "source": [
        "## Вопросы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeQIMvGVjdIZ"
      },
      "source": [
        "**В чем основные отличия между сверточной нейронной сетью и 'обычной' полносвязной нейронной сетью?**\n",
        "\n",
        "Основное отличие в том, **как они обрабатывают данные**.\n",
        "\n",
        "**Полносвязная сеть (FCNN):** Каждый нейрон в слое соединен со **всеми** нейронами предыдущего слоя. Это приводит к огромному количеству параметров, особенно для изображений, и не учитывает пространственную локальность пикселей (соседние пиксели важнее дальних).\n",
        "\n",
        "**Сверточная сеть (CNN):** Использует **сверточные слои**, где нейроны соединены только с небольшой локальной областью (ядром) предыдущего слоя. Это позволяет сети эффективно извлекать локальные признаки (например, края, текстуры) и обладает свойством **параметрической эффективности** (одни и те же веса ядра используются по всему изображению) и **эквивариантности к сдвигу** (признак будет обнаружен независимо от его положения на изображении).\n",
        "\n",
        "**Простой пример:** Для изображения 224x224x3 (150,528 пикселей) первый полносвязный слой с 1024 нейронами имел бы 150,528 * 1024 ≈ 154 миллиона параметров! В CNN первый сверточный слой с ядром 3x3 и 64 фильтрами имеет всего 3 * 3 * 3 * 64 = 1,728 параметров."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}